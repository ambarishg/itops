{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Ambarish\\itops\\.venv\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from itops.storage.azure_blob.azure_blob_helper import AzureBlobHelper\n",
    "from itops.storage.azure_blob.csv_helper import CSVHelper\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itops.db.mysql.mysqlhelper import MySQLHelper\n",
    "from itops.llm.azureopenaimanager.azure_open_ai_helper import AzureOpenAIManager\n",
    "from itops.config.configs import CONFIGS\n",
    "mysql_helper = MySQLHelper(CONFIGS.HOST,\n",
    "                           CONFIGS.USERNAME_MYSQL,\n",
    "                           CONFIGS.PASSWORD, \"itops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID_request', 'Text', 'Category', 'Solution', 'Date_request_recieved',\n",
      "       'Date_request_solved', 'ID_agent', 'themes', 'embeddings', 'CLUSTERS',\n",
      "       'CLUSTER_NAMES'],\n",
      "      dtype='object') 118\n"
     ]
    }
   ],
   "source": [
    "# Read a Parquet file into a DataFrame\n",
    "df = pd.read_parquet('01.parquet')\n",
    "\n",
    "print(df.columns, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_column_name = \"Text\"\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "CATEGORY = \"ITSM1\"\n",
    "run_name = \"RUN004\"\n",
    "user_input = \"Please extract the theme of the provided context in Maximum 5 words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = 'ITSM_Data-RUN001-ITSM1-RUN002-ITSM1.csv'\n",
    "FILENAME = 'ITSM_Data-RUN001-ITSM1-DEVICE_RUN_001-ITSM1.csv'\n",
    "FILENAME = 'ITSM_Data-RUN001-ITSM1-RUN004-ITSM1.csv'\n",
    "CONTAINER_NAME = 'itops'\n",
    "ACCOUNT_NAME = 'stgtxtsql'\n",
    "blob_helper = AzureBlobHelper(account_name= ACCOUNT_NAME,\n",
    "                              container_name= CONTAINER_NAME,\n",
    "                              account_key=CONFIGS.AZURE_BLOB_STORAGE_KEY)\n",
    "csv_helper = CSVHelper(azure_blob_helper=blob_helper)\n",
    "df = csv_helper.read_csv(FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"themes\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"CLUSTER_NAMES\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CLUSTERS\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CLUSTER_NAMES\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CLUSTER_NAMES\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped = df.drop('embeddings', axis=1)\n",
    "df_dropped = df_dropped.drop('CLUSTERS', axis=1)\n",
    "df_dropped = df_dropped.drop('CLUSTER_NAMES', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_query_vector(query,model_name):\n",
    "        \"\"\"Get the vector of the query\n",
    "\n",
    "        Args:\n",
    "            query (string): user input\n",
    "\n",
    "        Returns:\n",
    "            _type_: vector of the query\n",
    "        \"\"\"\n",
    "        model = SentenceTransformer(model_name)\n",
    "        query_vector = model.encode(query)\n",
    "        return query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding_dataset(df):\n",
    "    embedding_list = []\n",
    "    for i in range(len(df)):\n",
    "        content = df.iloc[i][\"themes\"]\n",
    "        embedding = get_embedding_query_vector(content,MODEL_NAME)\n",
    "        embedding_list.append(embedding)\n",
    "        print(f\"Completed EMBEDDING  {i+1} ROW\")\n",
    "\n",
    "    df[\"embeddings\"] = embedding_list\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = generate_embedding_dataset(df_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a Parquet file\n",
    "df_new.to_parquet('PARQUET001.parquet', engine='pyarrow', compression='snappy')\n",
    "\n",
    "print(\"DataFrame saved to Parquet file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DataFrame back from the Parquet file\n",
    "loaded_df = pd.read_parquet('PARQUET001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "embedding_array = np.array(loaded_df[\"embeddings\"].tolist())\n",
    "kmeans.fit(embedding_array)\n",
    "labels = kmeans.labels_\n",
    "loaded_df[\"CLUSTERS\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_df[\"CLUSTERS\"].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
