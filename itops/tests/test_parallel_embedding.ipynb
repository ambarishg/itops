{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from itops.storage.azure_blob.azure_blob_helper import AzureBlobHelper\n",
    "from itops.config.configs import CONFIGS\n",
    "from itops.storage.azure_blob.parquet_helper import ParquetHelper\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the number of CPU cores\n",
    "num_of_cores = os.cpu_count()\n",
    "\n",
    "print(\"Number of CPU cores:\", num_of_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "FILENAME = 'ITSM_Data-RUN0007-ITSM-PARQUET-MINI.parquet'\n",
    "CONTAINER_NAME = 'itops'\n",
    "ACCOUNT_NAME = 'stgtxtsql'\n",
    "blob_helper = AzureBlobHelper(account_name= ACCOUNT_NAME,\n",
    "                              container_name= CONTAINER_NAME,\n",
    "                              account_key=CONFIGS.AZURE_BLOB_STORAGE_KEY)\n",
    "file_helper = ParquetHelper(azure_blob_helper=blob_helper)\n",
    "df = file_helper.read_file(FILENAME)\n",
    "df_actual = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"themes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    def __init__(self, embedding_model_name):\n",
    "        self.embedding_model_name = embedding_model_name\n",
    "\n",
    "    def get_embedding_query_vector(self,query,model_name):\n",
    "        \"\"\"Get the vector of the query\n",
    "\n",
    "        Args:\n",
    "            query (string): user input\n",
    "\n",
    "        Returns:\n",
    "            _type_: vector of the query\n",
    "        \"\"\"\n",
    "        model = SentenceTransformer(self.embedding_model_name)\n",
    "        query_vector = model.encode(query)\n",
    "        return query_vector\n",
    "\n",
    "    def generate_embedding_dataset(self, df):\n",
    "        embedding_list = []\n",
    "\n",
    "        def embed_row(row):\n",
    "            content = row[\"themes\"]\n",
    "            embedding = self.get_embedding_query_vector(content, self.embedding_model_name)\n",
    "            print(f\"Completed EMBEDDING for ROW: {row.name + 1}\")  # row.name gives the index\n",
    "            return np.array(embedding)\n",
    "\n",
    "        # Use ThreadPoolExecutor for I/O bound tasks or ProcessPoolExecutor for CPU bound tasks\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            embedding_list = list(executor.map(embed_row, [df.iloc[i] for i in range(len(df))]))\n",
    "\n",
    "        df[\"embeddings\"] = embedding_list\n",
    "        return df\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.DataFrame({\"themes\": [\"text1\", \"text2\", \"text3\"]})\n",
    "# generator = EmbeddingGenerator(\"your_model_name\")\n",
    "# df_with_embeddings = generator.generate_embedding_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = EmbeddingGenerator(MODEL_NAME)\n",
    "df_with_embeddings = generator.generate_embedding_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_query_vector(query,model_name):\n",
    "        \n",
    "        \"\"\"Get the vector of the query\n",
    "\n",
    "        Args:\n",
    "            query (string): user input\n",
    "\n",
    "        Returns:\n",
    "            _type_: vector of the query\n",
    "        \"\"\"\n",
    "        model = SentenceTransformer(model_name)\n",
    "        query_vector = model.encode(query)\n",
    "        return query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = []\n",
    "for i in range(len(df)):\n",
    "    content = df.iloc[i][\"themes\"]\n",
    "    embedding = get_embedding_query_vector(content,MODEL_NAME)\n",
    "    embedding_list.append(embedding)\n",
    "    print(f\"Completed {i+1} ROW\")\n",
    "df[\"embeddings\"] = embedding_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert embeddings to NumPy arrays for efficient comparison\n",
    "arr1 = np.array(df_with_embeddings['embeddings'].tolist())\n",
    "arr2 = np.array(df['embeddings'].tolist())\n",
    "\n",
    "# Check for equality\n",
    "equal_rows = np.array_equal(arr1, arr2)\n",
    "print(\"Are all embeddings equal:\", equal_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
